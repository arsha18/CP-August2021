{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the Bagging scratch code in our lecture such that:\n",
    "\n",
    "Calculate for oob evaluation for each bootstrapped dataset, and also the average score\n",
    "\n",
    "Change the code to \"without replacement\"\n",
    "\n",
    "Put everything into a class Bagging. It should have at least two methods, fit(X_train, y_train), and predict(X_test)\n",
    "\n",
    "Modify the code from above to randomize features. Set the number of features to be used in each tree to be sqrt(n), and then select a subset of features for each tree. This can be easily done by setting our DecisionTreeClassifier max_features to 'sqrt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Out of bag score for each tree====\n",
      "Tree 0 0.9523809523809523\n",
      "Tree 1 0.9523809523809523\n",
      "Tree 2 0.9047619047619048\n",
      "Tree 3 0.8095238095238095\n",
      "Tree 4 0.7619047619047619\n",
      "====Average out of bag score====\n",
      "0.8761904761904761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random, math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, B, bootstrap_ratio, with_no_replacement=True):\n",
    "        self.B = B\n",
    "        self.bootstrap_ratio = bootstrap_ratio\n",
    "        self.with_no_replacement = with_no_replacement\n",
    "        self.tree_params = {'max_depth': 2, 'max_features': 'sqrt'}\n",
    "        self.models = [DecisionTreeClassifier(**self.tree_params) for _ in range(B)]\n",
    "        \n",
    "                    \n",
    "    def fit(self, X, y):  \n",
    "        m, n = X.shape\n",
    "\n",
    "        #sample size for each tree\n",
    "        sample_size = int(self.bootstrap_ratio * len(X))\n",
    "\n",
    "        xsamples = np.zeros((self.B, sample_size, n))\n",
    "        ysamples = np.zeros((self.B, sample_size))\n",
    "\n",
    "        xsamples_oob = []  \n",
    "        ysamples_oob = []\n",
    "         \n",
    "        #bootstrapping samples for each model\n",
    "        for i in range(self.B):\n",
    "            oob_idx = []\n",
    "            idxes = []\n",
    "            for j in range(sample_size):\n",
    "                idx = random.randrange(m)\n",
    "                if (self.with_no_replacement):\n",
    "                    while idx in idxes:\n",
    "                        idx = random.randrange(m)\n",
    "                idxes.append(idx)\n",
    "                oob_idx.append(idx)\n",
    "                xsamples[i, j, :] = X[idx]\n",
    "                ysamples[i, j] = y[idx]\n",
    "            mask = np.zeros((m), dtype=bool)\n",
    "            mask[oob_idx] = True\n",
    "            xsamples_oob.append(X[~mask])\n",
    "            ysamples_oob.append(y[~mask])     \n",
    "             \n",
    "        #fitting each estimator\n",
    "        oob_score = 0\n",
    "        print(\"====Out of bag score for each tree====\")\n",
    "        for i, model in enumerate(self.models):\n",
    "            \n",
    "            _X = xsamples[i]\n",
    "            _y = ysamples[i]\n",
    "            model.fit(_X, _y)\n",
    "\n",
    "            #calculating oob score\n",
    "            _X_test = np.asarray(xsamples_oob[i])\n",
    "            _y_test = np.asarray(ysamples_oob[i])\n",
    "            yhat = model.predict(_X_test)\n",
    "            oob_score += accuracy_score(_y_test, yhat)\n",
    "            print(f\"Tree {i}\", accuracy_score(_y_test, yhat))\n",
    "        self.avg_oob_score = oob_score / len(self.models)\n",
    "        print(\"====Average out of bag score====\")\n",
    "        print(self.avg_oob_score)\n",
    "        \n",
    "    def predict(self, X): \n",
    "        #make prediction and return the probabilities\n",
    "        predictions = np.zeros((self.B, X.shape[0]))\n",
    "        for i, model in enumerate(self.models):\n",
    "            yhat = model.predict(X)\n",
    "            predictions[i, :] = yhat\n",
    "        return stats.mode(predictions)[0][0]\n",
    "\n",
    "model = RandomForest(B=5, bootstrap_ratio=0.8)\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
